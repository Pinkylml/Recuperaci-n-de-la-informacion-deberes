{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workshop: Building an Information Retrieval System for Podcast Episodes\n",
    "\n",
    "**Objective:**\n",
    "Create an Information Retrieval (IR) system that processes a dataset of podcast transcripts and, given a query, returns the episodes where the host and guest discuss the query topic. Use TF-IDF and BERT for vector space representation and compare the results.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "**Step 1: Import Libraries**\n",
    "Import necessary libraries for data handling, text processing, and machine learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Load the Dataset**\n",
    "Load the dataset of podcast transcripts.\n",
    "\n",
    "Find the dataset in: https://www.kaggle.com/datasets/rajneesh231/lex-fridman-podcast-transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Text Preprocessing**\n",
    "\n",
    "You know what to do ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>guest</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Max Tegmark</td>\n",
       "      <td>Life 3.0</td>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Christof Koch</td>\n",
       "      <td>Consciousness</td>\n",
       "      <td>As part of MIT course 6S099 on artificial gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Steven Pinker</td>\n",
       "      <td>AI in the Age of Reason</td>\n",
       "      <td>You've studied the human mind, cognition, lang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Yoshua Bengio</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>What difference between biological neural netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vladimir Vapnik</td>\n",
       "      <td>Statistical Learning</td>\n",
       "      <td>The following is a conversation with Vladimir ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>321</td>\n",
       "      <td>Ray Kurzweil</td>\n",
       "      <td>Singularity, Superintelligence, and Immortality</td>\n",
       "      <td>By the time he gets to 2045, we'll be able to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>322</td>\n",
       "      <td>Rana el Kaliouby</td>\n",
       "      <td>Emotion AI, Social Robots, and Self-Driving Cars</td>\n",
       "      <td>there's a broader question here, right? As we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>323</td>\n",
       "      <td>Will Sasso</td>\n",
       "      <td>Comedy, MADtv, AI, Friendship, Madness, and Pr...</td>\n",
       "      <td>Once this whole thing falls apart and we are c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>324</td>\n",
       "      <td>Daniel Negreanu</td>\n",
       "      <td>Poker</td>\n",
       "      <td>you could be the seventh best player in the wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>325</td>\n",
       "      <td>Michael Levin</td>\n",
       "      <td>Biology, Life, Aliens, Evolution, Embryogenesi...</td>\n",
       "      <td>turns out that if you train a planarian and th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id             guest                                              title  \\\n",
       "0      1       Max Tegmark                                           Life 3.0   \n",
       "1      2     Christof Koch                                      Consciousness   \n",
       "2      3     Steven Pinker                            AI in the Age of Reason   \n",
       "3      4     Yoshua Bengio                                      Deep Learning   \n",
       "4      5   Vladimir Vapnik                               Statistical Learning   \n",
       "..   ...               ...                                                ...   \n",
       "314  321      Ray Kurzweil    Singularity, Superintelligence, and Immortality   \n",
       "315  322  Rana el Kaliouby   Emotion AI, Social Robots, and Self-Driving Cars   \n",
       "316  323        Will Sasso  Comedy, MADtv, AI, Friendship, Madness, and Pr...   \n",
       "317  324   Daniel Negreanu                                              Poker   \n",
       "318  325     Michael Levin  Biology, Life, Aliens, Evolution, Embryogenesi...   \n",
       "\n",
       "                                                  text  \n",
       "0    As part of MIT course 6S099, Artificial Genera...  \n",
       "1    As part of MIT course 6S099 on artificial gene...  \n",
       "2    You've studied the human mind, cognition, lang...  \n",
       "3    What difference between biological neural netw...  \n",
       "4    The following is a conversation with Vladimir ...  \n",
       "..                                                 ...  \n",
       "314  By the time he gets to 2045, we'll be able to ...  \n",
       "315  there's a broader question here, right? As we ...  \n",
       "316  Once this whole thing falls apart and we are c...  \n",
       "317  you could be the seventh best player in the wh...  \n",
       "318  turns out that if you train a planarian and th...  \n",
       "\n",
       "[319 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"data/podcastdata_dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=319, step=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in df['text']:\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
